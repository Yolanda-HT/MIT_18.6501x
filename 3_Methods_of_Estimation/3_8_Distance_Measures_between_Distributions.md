## Objectives
*Total Variation Distance, Kullback-Leibler (KL) divergence, and the Maximum Likelihood Principle*

At the end of this lecture, you will be able to do the following:

- Describe properties of the total variation distance and Kullback-Leibler (KL) divergence.

- Compute the total variation distance and KL divergence between two distributions.

- Derive the maximum likelihood principle using the KL divergence.

- Define and compute the likelihood of a discrete distribution.